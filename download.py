#!/usr/bin/env python3
"""
YouTube Video Downloader
–°–∫–∞—á–∏–≤–∞–µ—Ç –≤–∏–¥–µ–æ —Å YouTube –≤ –∫–∞—á–µ—Å—Ç–≤–µ 720p –∏–ª–∏ 1080p
"""

import os
import sys
import argparse
from pathlib import Path
import yt_dlp

# –ó–∞–≥—Ä—É–∂–∞–µ–º .env –µ—Å–ª–∏ –µ—Å—Ç—å
_env_path = Path(__file__).parent / '.env'
if _env_path.exists():
    for line in _env_path.read_text().strip().splitlines():
        if '=' in line and not line.startswith('#'):
            k, v = line.split('=', 1)
            os.environ.setdefault(k.strip(), v.strip())

DEFAULT_PROXY = os.environ.get('YTDL_PROXY', '')


def list_videos(url: str, output_dir: str = "./downloads", proxy: str = None):
    """–ü–∞—Ä—Å–∏—Ç –∫–∞–Ω–∞–ª/–ø–ª–µ–π–ª–∏—Å—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ø–∏—Å–æ–∫ –≤–∏–¥–µ–æ –≤ CSV"""
    import csv

    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    opts = {
        'quiet': True,
        'no_warnings': True,
        'extract_flat': 'in_playlist',
        'ignoreerrors': True,
        'extractor_args': {'youtube': {'player_client': ['android', 'web']}},
    }
    if proxy:
        opts['proxy'] = proxy

    print(f"üìã –ü–æ–ª—É—á–∞—é —Å–ø–∏—Å–æ–∫ –≤–∏–¥–µ–æ...")
    print(f"üîó URL: {url}")
    if proxy:
        print(f"üåê –ü—Ä–æ–∫—Å–∏: {proxy}")

    with yt_dlp.YoutubeDL(opts) as ydl:
        info = ydl.extract_info(url, download=False)

    title = info.get('title', 'videos')
    entries = list(info.get('entries', []))

    # –î–ª—è –∫–∞–Ω–∞–ª–æ–≤ title –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å " - Videos", —É–±–∏—Ä–∞–µ–º
    clean_title = title.replace(' - Videos', '').replace(' - –í–∏–¥–µ–æ', '').strip()
    safe_title = "".join(c if c.isalnum() or c in ' .-_' else '_' for c in clean_title)
    csv_path = output_path / f"{safe_title}.csv"

    rows = []
    for entry in entries:
        vid_title = entry.get('title', '')
        vid_id = entry.get('id', '')
        vid_url = f"https://www.youtube.com/watch?v={vid_id}" if vid_id else entry.get('url', '')
        if vid_title or vid_id:
            rows.append((vid_title, vid_url))

    with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        writer.writerow(['title', 'url'])
        writer.writerows(rows)

    print(f"\n‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(rows)} –≤–∏–¥–µ–æ –≤ {csv_path}")


def srt_to_text(srt_path: Path, chunk_minutes: int = 5) -> str:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç SRT –≤ —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç —Å —Ä–∞–∑–±–∏–≤–∫–æ–π –ø–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º"""
    import re

    content = srt_path.read_text(encoding='utf-8', errors='replace')

    entries = []
    for block in re.split(r'\n\s*\n', content.strip()):
        lines = block.strip().split('\n')
        if len(lines) < 3:
            continue
        # –ü–∞—Ä—Å–∏–º —Ç–∞–π–º–∫–æ–¥: 00:01:23,456 --> 00:01:25,789
        tc_match = re.match(r'(\d{2}):(\d{2}):(\d{2})', lines[1])
        if not tc_match:
            continue
        h, m, s = int(tc_match.group(1)), int(tc_match.group(2)), int(tc_match.group(3))
        seconds = h * 3600 + m * 60 + s
        text = ' '.join(lines[2:]).strip()
        # –£–±–∏—Ä–∞–µ–º HTML-—Ç–µ–≥–∏ –∏ –¥—É–±–ª–∏–∫–∞—Ç—ã –æ—Ç YouTube auto-subs
        text = re.sub(r'<[^>]+>', '', text)
        if text:
            entries.append((seconds, text))

    if not entries:
        return ''

    # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è (YouTube –∞–≤—Ç–æ-—Å—É–±—Ç–∏—Ç—Ä—ã —á–∞—Å—Ç–æ –¥—É–±–ª–∏—Ä—É—é—Ç —Å—Ç—Ä–æ–∫–∏)
    seen = set()
    unique = []
    for sec, text in entries:
        if text not in seen:
            seen.add(text)
            unique.append((sec, text))

    # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ chunk_minutes-–º–∏–Ω—É—Ç–Ω—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º
    chunk_sec = chunk_minutes * 60
    chunks = []
    current_chunk = []
    current_boundary = chunk_sec

    for sec, text in unique:
        if sec >= current_boundary and current_chunk:
            chunks.append((current_boundary - chunk_sec, current_chunk))
            current_chunk = []
            current_boundary = (sec // chunk_sec + 1) * chunk_sec
        current_chunk.append(text)

    if current_chunk:
        chunks.append((current_boundary - chunk_sec, current_chunk))

    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º
    parts = []
    for start_sec, texts in chunks:
        h, m = start_sec // 3600, (start_sec % 3600) // 60
        label = f"[{h:02d}:{m:02d}]" if h > 0 else f"[{m:02d}:00]"
        parts.append(f"{label}\n{' '.join(texts)}")

    return '\n\n'.join(parts)


def download_text(url: str, output_dir: str = "./downloads", proxy: str = None, subs_lang: str = "ru", chunk_minutes: int = 5):
    """–°–∫–∞—á–∏–≤–∞–µ—Ç —Å—É–±—Ç–∏—Ç—Ä—ã –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤ —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç"""
    output_path = Path(output_dir)
    text_path = output_path / 'out-text'
    text_path.mkdir(parents=True, exist_ok=True)

    # –°–Ω–∞—á–∞–ª–∞ —Å–∫–∞—á–∏–≤–∞–µ–º SRT –≤ temp
    import tempfile
    with tempfile.TemporaryDirectory() as tmpdir:
        tmp = Path(tmpdir)
        ydl_opts = {
            'outtmpl': str(tmp / '%(playlist_index|)s%(playlist_index&. |)s%(title)s.%(ext)s'),
            'quiet': False,
            'no_warnings': True,
            'ignoreerrors': True,
            'sleep_interval': 3,
            'max_sleep_interval': 6,
            'skip_download': True,
            'writeautomaticsub': True,
            'writesubtitles': True,
            'subtitleslangs': [subs_lang],
            'subtitlesformat': 'srt',
            'postprocessors': [{'key': 'FFmpegSubtitlesConvertor', 'format': 'srt'}],
            'extractor_args': {'youtube': {'player_client': ['android', 'web']}},
        }
        if proxy:
            ydl_opts['proxy'] = proxy

        print(f"üìù –°–∫–∞—á–∏–≤–∞—é —Å—É–±—Ç–∏—Ç—Ä—ã –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É—é –≤ —Ç–µ–∫—Å—Ç...")
        print(f"üîó URL: {url}")
        if proxy:
            print(f"üåê –ü—Ä–æ–∫—Å–∏: {proxy}")
        print(f"üìÅ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤: {text_path.absolute()}\n")

        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            ydl.download([url])

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ —Å–∫–∞—á–∞–Ω–Ω—ã–µ SRT –≤ —Ç–µ–∫—Å—Ç
        srt_files = sorted(tmp.glob(f'*.{subs_lang}.srt'))
        if not srt_files:
            print("‚ö†Ô∏è  –°—É–±—Ç–∏—Ç—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return

        for srt_file in srt_files:
            # –ò–º—è –±–µ–∑ —è–∑—ã–∫–æ–≤–æ–≥–æ —Å—É—Ñ—Ñ–∏–∫—Å–∞
            name = srt_file.stem
            if name.endswith(f'.{subs_lang}'):
                name = name[:-len(f'.{subs_lang}')]
            txt_file = text_path / f"{name}.txt"

            text = srt_to_text(srt_file, chunk_minutes)
            if text:
                txt_file.write_text(text, encoding='utf-8')
                print(f"  ‚úÖ {txt_file.name}")
            else:
                print(f"  ‚ö†Ô∏è  –ü—É—Å—Ç—ã–µ —Å—É–±—Ç–∏—Ç—Ä—ã: {srt_file.name}")

    print(f"\n‚úÖ –¢–µ–∫—Å—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {text_path}")


def download_video(url: str, quality: str = "1080", output_dir: str = "./downloads", mp3: bool = False, proxy: str = None, cookies_browser: str = None, subs: bool = False, subs_lang: str = "ru"):
    """
    –°–∫–∞—á–∏–≤–∞–µ—Ç –≤–∏–¥–µ–æ —Å YouTube –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º –∫–∞—á–µ—Å—Ç–≤–µ

    Args:
        url: URL –≤–∏–¥–µ–æ –Ω–∞ YouTube
        quality: –ö–∞—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ (720 –∏–ª–∏ 1080)
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–∏–¥–µ–æ
        mp3: –°–∫–∞—á–∞—Ç—å —Ç–æ–ª—å–∫–æ –∞—É–¥–∏–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ MP3
        proxy: –ü—Ä–æ–∫—Å–∏-—Å–µ—Ä–≤–µ—Ä (–Ω–∞–ø—Ä–∏–º–µ—Ä, http://ip:port)
    """
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∑–∞–≥—Ä—É–∑–æ–∫, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    # –ë–∞–∑–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è yt-dlp
    ydl_opts = {
        'outtmpl': str(output_path / '%(playlist_title|)s%(playlist_title&/|)s%(playlist_index|)s%(playlist_index&. |)s%(title)s.%(ext)s'),
        'quiet': False,
        'no_warnings': True,
        'ignoreerrors': True,
        'download_archive': str(output_path / '.archive.txt'),
        'sleep_interval': 3,
        'max_sleep_interval': 6,
        'progress_hooks': [progress_hook],
        'extractor_args': {'youtube': {'player_client': ['android', 'web']}},
        'http_headers': {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        },
    }

    if proxy:
        ydl_opts['proxy'] = proxy

    if cookies_browser:
        ydl_opts['cookiesfrombrowser'] = (cookies_browser,)

    if subs:
        ydl_opts['skip_download'] = True
        ydl_opts['writeautomaticsub'] = True
        ydl_opts['writesubtitles'] = True
        ydl_opts['subtitleslangs'] = [subs_lang]
        ydl_opts['subtitlesformat'] = 'srt'
        ydl_opts['postprocessors'] = [{'key': 'FFmpegSubtitlesConvertor', 'format': 'srt'}]
    elif mp3:
        ydl_opts['format'] = 'worstaudio/worst'
        ydl_opts['postprocessors'] = [{
            'key': 'FFmpegExtractAudio',
            'preferredcodec': 'mp3',
            'preferredquality': '64',
        }]
    else:
        ydl_opts['format'] = f'bestvideo[height<={quality}]+bestaudio/best[height<={quality}]'
        ydl_opts['merge_output_format'] = 'mp4'

    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            if subs:
                print(f"üìù –°–∫–∞—á–∏–≤–∞—é —Å—É–±—Ç–∏—Ç—Ä—ã ({subs_lang})...")
            elif mp3:
                print(f"üéµ –°–∫–∞—á–∏–≤–∞—é –∞—É–¥–∏–æ –≤ MP3...")
            else:
                print(f"üì• –°–∫–∞—á–∏–≤–∞—é –≤–∏–¥–µ–æ –≤ –∫–∞—á–µ—Å—Ç–≤–µ {quality}p...")
            print(f"üîó URL: {url}")
            if proxy:
                print(f"üåê –ü—Ä–æ–∫—Å–∏: {proxy}")
            print(f"üìÅ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤: {output_path.absolute()}\n")

            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∏–¥–µ–æ/–ø–ª–µ–π–ª–∏—Å—Ç–µ
            info = ydl.extract_info(url, download=False)

            if info.get('_type') == 'playlist':
                entries = info.get('entries', [])
                count = info.get('playlist_count') or len(list(entries))
                print(f"üìã –ü–ª–µ–π–ª–∏—Å—Ç: {info.get('title', 'Unknown')}")
                print(f"üìä –í–∏–¥–µ–æ –≤ –ø–ª–µ–π–ª–∏—Å—Ç–µ: {count}\n")
            else:
                print(f"üìπ –ù–∞–∑–≤–∞–Ω–∏–µ: {info.get('title', 'Unknown')}")
                duration = info.get('duration', 0) or 0
                print(f"‚è±Ô∏è  –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration // 60} –º–∏–Ω {duration % 60} —Å–µ–∫\n")

            # –°–∫–∞—á–∏–≤–∞–µ–º
            ydl.download([url])

            if subs:
                print("\n‚úÖ –°—É–±—Ç–∏—Ç—Ä—ã —Å–∫–∞—á–∞–Ω—ã!")
            elif mp3:
                print("\n‚úÖ MP3 —É—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω!")
            else:
                print("\n‚úÖ –í–∏–¥–µ–æ —É—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω–æ!")

    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏: {e}", file=sys.stderr)
        sys.exit(1)


def progress_hook(d):
    """–•—É–∫ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è"""
    if d['status'] == 'downloading':
        if d.get('total_bytes'):
            percent = d['downloaded_bytes'] / d['total_bytes'] * 100
            print(f"\r‚¨áÔ∏è  –ü—Ä–æ–≥—Ä–µ—Å—Å: {percent:.1f}%", end='', flush=True)
        elif '_percent_str' in d:
            print(f"\r‚¨áÔ∏è  –ü—Ä–æ–≥—Ä–µ—Å—Å: {d['_percent_str']}", end='', flush=True)
    elif d['status'] == 'finished':
        print(f"\nüîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ...")


def main():
    parser = argparse.ArgumentParser(
        description='–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ/–∞—É–¥–∏–æ/—Å—É–±—Ç–∏—Ç—Ä–æ–≤ —Å YouTube (–≤–∏–¥–µ–æ, –ø–ª–µ–π–ª–∏—Å—Ç—ã, –∫–∞–Ω–∞–ª—ã)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  uv run python download.py URL                              # –≤–∏–¥–µ–æ 1080p
  uv run python download.py URL -q 720                       # –≤–∏–¥–µ–æ 720p
  uv run python download.py URL --mp3 --ru                   # MP3 —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏ (–†–§)
  uv run python download.py URL -p http://ip:port            # —Å–≤–æ–π –ø—Ä–æ–∫—Å–∏
  uv run python download.py URL -q 1080 -o ./my_videos       # –≤ —Å–≤–æ—é –ø–∞–ø–∫—É
  uv run python download.py PLAYLIST_URL --mp3 --ru          # –ø–ª–µ–π–ª–∏—Å—Ç –≤ MP3
  uv run python download.py URL --subs --ru                  # —Å—É–±—Ç–∏—Ç—Ä—ã (ru)
  uv run python download.py URL --subs --subs-lang en --ru   # —Å—É–±—Ç–∏—Ç—Ä—ã (en)
  uv run python download.py @CHANNEL --subs --ru             # —Å—É–±—Ç–∏—Ç—Ä—ã –≤—Å–µ–≥–æ –∫–∞–Ω–∞–ª–∞
  uv run python download.py @CHANNEL --list --ru             # —Å–ø–∏—Å–æ–∫ –≤–∏–¥–µ–æ –≤ CSV
  uv run python download.py URL --text --ru                  # —Å—É–±—Ç–∏—Ç—Ä—ã -> —Ç–µ–∫—Å—Ç
  uv run python download.py URL1 URL2 --text --ru            # –Ω–µ—Å–∫–æ–ª—å–∫–æ URL —Å—Ä–∞–∑—É

URL –º–æ–∂–µ—Ç –±—ã—Ç—å –≤–∏–¥–µ–æ, –ø–ª–µ–π–ª–∏—Å—Ç–æ–º –∏–ª–∏ –∫–∞–Ω–∞–ª–æ–º:
  https://www.youtube.com/watch?v=VIDEO_ID
  https://www.youtube.com/playlist?list=PLAYLIST_ID
  https://www.youtube.com/@ChannelName
        """
    )

    parser.add_argument(
        'url',
        help='URL –≤–∏–¥–µ–æ –∏–ª–∏ –ø–ª–µ–π–ª–∏—Å—Ç–∞ –Ω–∞ YouTube'
    )

    parser.add_argument(
        '-q', '--quality',
        choices=['720', '1080'],
        default='1080',
        help='–ö–∞—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 1080)'
    )

    parser.add_argument(
        '-o', '--output',
        default='./downloads',
        help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: ./downloads)'
    )

    parser.add_argument(
        '--mp3',
        action='store_true',
        help='–°–∫–∞—á–∞—Ç—å —Ç–æ–ª—å–∫–æ –∞—É–¥–∏–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ MP3'
    )

    parser.add_argument(
        '-p', '--proxy',
        help='–ü—Ä–æ–∫—Å–∏-—Å–µ—Ä–≤–µ—Ä (–Ω–∞–ø—Ä–∏–º–µ—Ä, http://ip:port –∏–ª–∏ socks5://ip:port)'
    )

    parser.add_argument(
        '--ru',
        action='store_true',
        help='–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ–∫—Å–∏ –∏–∑ YTDL_PROXY (–¥–ª—è –†–§)'
    )

    parser.add_argument(
        '-c', '--cookies',
        choices=['chrome', 'firefox', 'edge', 'brave', 'opera'],
        help='–í–∑—è—Ç—å –∫—É–∫–∏ –∏–∑ –±—Ä–∞—É–∑–µ—Ä–∞ (chrome, firefox, edge, brave, opera)'
    )

    parser.add_argument(
        '--subs',
        action='store_true',
        help='–°–∫–∞—á–∞—Ç—å —Ç–æ–ª—å–∫–æ —Å—É–±—Ç–∏—Ç—Ä—ã (–∞–≤—Ç–æ + —Ä—É—á–Ω—ã–µ) –≤ .srt'
    )

    parser.add_argument(
        '--subs-lang',
        default='ru',
        help='–Ø–∑—ã–∫ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: ru)'
    )

    parser.add_argument(
        '--list',
        action='store_true',
        help='–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤–∏–¥–µ–æ –∫–∞–Ω–∞–ª–∞/–ø–ª–µ–π–ª–∏—Å—Ç–∞ –≤ CSV (–Ω–∞–∑–≤–∞–Ω–∏–µ, —Å—Å—ã–ª–∫–∞)'
    )

    parser.add_argument(
        '--text',
        action='store_true',
        help='–°–∫–∞—á–∞—Ç—å —Å—É–±—Ç–∏—Ç—Ä—ã –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç (out-text/*.txt)'
    )

    parser.add_argument(
        '--chunk',
        type=int,
        default=5,
        help='–†–∞–∑–º–µ—Ä –±–ª–æ–∫–∞ —Ç–µ–∫—Å—Ç–∞ –≤ –º–∏–Ω—É—Ç–∞—Ö –¥–ª—è --text (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 5)'
    )

    parser.add_argument(
        'extra_urls',
        nargs='*',
        help='–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ URL –¥–ª—è –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏'
    )

    args = parser.parse_args()

    proxy = args.proxy
    if args.ru:
        proxy = DEFAULT_PROXY

    urls = [args.url] + (args.extra_urls or [])

    if args.list:
        for u in urls:
            list_videos(u, args.output, proxy)
    elif args.text:
        for u in urls:
            download_text(u, args.output, proxy, args.subs_lang, args.chunk)
    else:
        for u in urls:
            download_video(u, args.quality, args.output, args.mp3, proxy, args.cookies, args.subs, args.subs_lang)


if __name__ == "__main__":
    main()
